"""
API FastAPI pour la pr√©diction de churn client
"""
import logging
import traceback
from datetime import datetime
from typing import Dict, Any, Optional

from fastapi import FastAPI, HTTPException, Query, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import ValidationError

# Imports locaux
from api.models import (
    ClientInputAPI,
    PredictionResponse, 
    HealthResponse,
    ModelInfoResponse,
    FakeClientResponse,
    ErrorResponse
)
from api.fake_data import generate_fake_client, get_available_profile_types, get_profile_description
from src.model_wrapper import ChurnPredictor

# Configuration logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# =====================================================
# INITIALISATION DE L'APPLICATION FASTAPI
# =====================================================

app = FastAPI(
    title="üéØ Churn Prediction API",
    description="""
    **API de pr√©diction de churn client pour t√©l√©communications**
    
    Cette API utilise un mod√®le XGBoost optimis√© pour pr√©dire le risque de churn
    des clients t√©l√©coms avec 11 features et un seuil business optimal.
    
    ## Fonctionnalit√©s principales :
    - **Pr√©diction client unique** avec recommandations business
    - **G√©n√©ration de clients fictifs** pour d√©monstration
    - **Health checks** et monitoring
    - **M√©tadonn√©es mod√®le** pour transparence
    
    ## Mod√®le utilis√© :
    - **Type** : XGBoost Champion 11 Features
    - **Recall** : 88.5% (objectif >80% ‚úÖ)
    - **Seuil optimal** : 35.10%
    - **Business Score** : Optimis√© pour co√ªts acquisition/r√©tention
    """,
    version="1.0.0",
    contact={
        "name": "EP-Portfolio",
        "email": "m.eddyponton@gmail.com"
    },
    license_info={
        "name": "MIT License"
    }
)

# =====================================================
# CONFIGURATION CORS
# =====================================================

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, sp√©cifier les domaines autoris√©s
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# =====================================================
# INITIALISATION DU PR√âDICTEUR
# =====================================================

predictor = None

@app.on_event("startup")
async def startup_event():
    """Initialisation au d√©marrage de l'API"""
    global predictor
    try:
        logger.info("üöÄ D√©marrage de l'API Churn Prediction...")
        predictor = ChurnPredictor()
        logger.info("‚úÖ Pr√©dicteur charg√© avec succ√®s")
        
        # Test de fonctionnement
        health = predictor.health_check()
        if health["status"] != "healthy":
            logger.warning(f"‚ö†Ô∏è Pr√©dicteur en √©tat d√©grad√©: {health}")
        else:
            logger.info("‚úÖ Health check initial: OK")
            
    except Exception as e:
        logger.error(f"‚ùå Erreur lors du d√©marrage: {e}")
        traceback.print_exc()
        raise

@app.on_event("shutdown")
async def shutdown_event():
    """Nettoyage √† l'arr√™t"""
    logger.info("üõë Arr√™t de l'API Churn Prediction")

# =====================================================
# GESTIONNAIRE D'ERREURS GLOBAL
# =====================================================

@app.exception_handler(ValidationError)
async def validation_exception_handler(request, exc):
    """Gestionnaire pour les erreurs de validation Pydantic"""
    logger.error(f"Erreur de validation: {exc}")
    return JSONResponse(
        status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,
        content=ErrorResponse(
            error="ValidationError",
            message=f"Donn√©es invalides: {str(exc)}",
            timestamp=datetime.now().isoformat()
        ).dict()
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """Gestionnaire pour les erreurs g√©n√©rales"""
    logger.error(f"Erreur serveur: {exc}")
    traceback.print_exc()
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content=ErrorResponse(
            error="InternalServerError", 
            message="Erreur interne du serveur",
            timestamp=datetime.now().isoformat()
        ).dict()
    )

# =====================================================
# ENDPOINTS PRINCIPAUX
# =====================================================

@app.get("/", tags=["Root"])
async def root():
    """Endpoint racine avec informations g√©n√©rales"""
    return {
        "service": "Churn Prediction API",
        "version": "1.0.0",
        "status": "running",
        "documentation": "/docs",
        "health": "/health",
        "model_info": "/model/info"
    }

@app.post(
    "/predict/client",
    response_model=PredictionResponse,
    tags=["Prediction"],
    summary="Pr√©diction de churn pour un client",
    description="""
    **Effectue une pr√©diction de churn pour un client unique.**
    
    L'API prend en entr√©e les 7 caract√©ristiques business du client et retourne :
    - Probabilit√© de churn [0-1]
    - Pr√©diction binaire (0=stable, 1=churn)  
    - Niveau de risque interpr√©t√©
    - Recommandation d'action business
    - Score de confiance
    
    Le mod√®le calcule automatiquement les features engineered n√©cessaires.
    """
)
async def predict_client_churn(client_data: ClientInputAPI):
    """
    Pr√©diction de churn pour un client unique
    
    Args:
        client_data: Donn√©es du client (7 features)
        
    Returns:
        PredictionResponse: R√©sultat complet de la pr√©diction
        
    Raises:
        HTTPException: Si erreur dans la pr√©diction
    """
    if predictor is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Pr√©dicteur non initialis√©"
        )
    
    try:
        logger.info(f"üîÑ Pr√©diction pour client {client_data.client_id or 'anonyme'}")
        
        # Conversion en dict pour le pr√©dicteur
        input_dict = {
            "contract": client_data.contract,
            "tenure": client_data.tenure, 
            "monthly_charges": client_data.monthly_charges,
            "total_charges": client_data.total_charges,
            "payment_method": client_data.payment_method,
            "internet_service": client_data.internet_service,
            "paperless_billing": client_data.paperless_billing
        }
        
        # Pr√©diction
        result = predictor.predict_single(input_dict, client_data.client_id)
        
        # Conversion en r√©ponse API
        response = PredictionResponse(
            churn_probability=result.churn_probability,
            churn_prediction=result.churn_prediction,
            risk_level=result.risk_level,
            business_recommendation=result.business_recommendation,
            confidence_score=result.confidence_score,
            client_id=result.client_id,
            prediction_timestamp=result.prediction_timestamp,
            model_metadata=result.model_metadata
        )
        
        logger.info(f"‚úÖ Pr√©diction termin√©e: P={result.churn_probability:.4f}, Risk={result.risk_level}")
        return response
        
    except ValueError as e:
        logger.error(f"‚ùå Erreur de validation: {e}")
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e)
        )
    except Exception as e:
        logger.error(f"‚ùå Erreur pr√©diction: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur lors de la pr√©diction: {str(e)}"
        )

@app.get(
    "/health",
    response_model=HealthResponse,
    tags=["Monitoring"],
    summary="Health check du service",
    description="V√©rifie l'√©tat de sant√© du service et du mod√®le de pr√©diction"
)
async def health_check():
    """
    Health check du service
    
    Returns:
        HealthResponse: √âtat de sant√© complet
    """
    if predictor is None:
        return HealthResponse(
            status="unhealthy",
            model_loaded=False,
            threshold_loaded=False,
            preprocessor_ready=False,
            timestamp=datetime.now().isoformat(),
            test_prediction_success=False,
            test_error="Pr√©dicteur non initialis√©"
        )
    
    try:
        health_data = predictor.health_check()
        
        response = HealthResponse(
            status=health_data["status"],
            model_loaded=health_data["model_loaded"],
            threshold_loaded=health_data["threshold_loaded"], 
            preprocessor_ready=health_data["preprocessor_ready"],
            timestamp=health_data["timestamp"],
            test_prediction_success=health_data.get("test_prediction_success"),
            test_probability=health_data.get("test_probability"),
            test_error=health_data.get("test_error")
        )
        
        logger.info(f"Health check: {health_data['status']}")
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur health check: {e}")
        return HealthResponse(
            status="unhealthy",
            model_loaded=False,
            threshold_loaded=False,
            preprocessor_ready=False,
            timestamp=datetime.now().isoformat(),
            test_prediction_success=False,
            test_error=str(e)
        )

@app.get(
    "/model/info",
    response_model=ModelInfoResponse,
    tags=["Monitoring"],
    summary="Informations sur le mod√®le",
    description="Retourne les m√©tadonn√©es compl√®tes du mod√®le de pr√©diction"
)
async def get_model_info():
    """
    Informations sur le mod√®le charg√©
    
    Returns:
        ModelInfoResponse: M√©tadonn√©es compl√®tes du mod√®le
    """
    if predictor is None:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Pr√©dicteur non initialis√©"
        )
    
    try:
        model_info = predictor.get_model_info()
        
        response = ModelInfoResponse(
            model_status=model_info["model_status"],
            model_type=model_info.get("model_type", "Unknown"),
            optimal_threshold=model_info["optimal_threshold"],
            features_count=model_info["features_count"],
            last_loaded=model_info["last_loaded"],
            model_metrics=model_info.get("model_metrics"),
            hyperparameters=model_info.get("hyperparameters"),
            preprocessing_info=model_info.get("preprocessing_info")
        )
        
        logger.info("Informations mod√®le retourn√©es")
        return response
        
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration infos mod√®le: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur r√©cup√©ration infos: {str(e)}"
        )

@app.get(
    "/generate/fake-client",
    response_model=FakeClientResponse,
    tags=["Demo"],
    summary="G√©n√©ration de client fictif",
    description="""
    **G√©n√®re un client fictif avec Faker pour d√©monstration.**
    
    Types de profils disponibles :
    - **random** : Profil compl√®tement al√©atoire
    - **high_risk** : Client √† haut risque de churn
    - **stable** : Client fid√®le et stable  
    - **new** : Nouveau client (0-3 mois)
    - **premium** : Client premium (services haut de gamme)
    
    Utile pour tester l'API et faire des d√©monstrations.
    """
)
async def generate_fake_client_endpoint(
    profile_type: str = Query(
        default="random",
        description="Type de profil √† g√©n√©rer",
        enum=["random", "high_risk", "stable", "new", "premium"]
    )
):
    """
    G√©n√®re un client fictif pour d√©monstration
    
    Args:
        profile_type: Type de profil √† g√©n√©rer
        
    Returns:
        FakeClientResponse: Client g√©n√©r√© avec m√©tadonn√©es
    """
    try:
        logger.info(f"üé≠ G√©n√©ration client fictif: {profile_type}")
        
        # G√©n√©ration du client fictif
        fake_client_data = generate_fake_client(profile_type)
        
        # Conversion en mod√®le API
        client_input = ClientInputAPI(**fake_client_data)
        
        response = FakeClientResponse(
            client_data=client_input,
            profile_type=profile_type,
            generation_timestamp=datetime.now().isoformat()
        )
        
        logger.info(f"‚úÖ Client fictif g√©n√©r√©: {profile_type}")
        return response
        
    except ValueError as e:
        logger.error(f"‚ùå Type de profil invalide: {e}")
        available_types = get_available_profile_types()
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=f"Type de profil invalide. Types disponibles: {available_types}"
        )
    except Exception as e:
        logger.error(f"‚ùå Erreur g√©n√©ration client fictif: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur g√©n√©ration: {str(e)}"
        )

@app.get(
    "/generate/profile-types",
    tags=["Demo"],
    summary="Types de profils disponibles",
    description="Liste tous les types de profils clients fictifs disponibles avec descriptions"
)
async def get_profile_types():
    """
    Liste des types de profils disponibles pour la g√©n√©ration
    
    Returns:
        Dict avec types et descriptions
    """
    try:
        profile_types = get_available_profile_types()
        
        profiles_info = {}
        for profile_type in profile_types:
            profiles_info[profile_type] = get_profile_description(profile_type)
        
        return {
            "available_profiles": profile_types,
            "descriptions": profiles_info,
            "usage": "Utilisez /generate/fake-client?profile_type=TYPE"
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur r√©cup√©ration types profils: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=str(e)
        )

# =====================================================
# ENDPOINT DE D√âMONSTRATION COMPL√àTE
# =====================================================

@app.get(
    "/demo/predict-fake-client",
    response_model=Dict[str, Any],
    tags=["Demo"],
    summary="D√©monstration compl√®te : g√©n√©ration + pr√©diction",
    description="G√©n√®re un client fictif ET fait la pr√©diction en une seule requ√™te"
)
async def demo_predict_fake_client(
    profile_type: str = Query(
        default="random",
        description="Type de profil √† g√©n√©rer et pr√©dire",
        enum=["random", "high_risk", "stable", "new", "premium"]
    )
):
    """
    D√©monstration compl√®te : g√©n√®re un client fictif et fait la pr√©diction
    
    Args:
        profile_type: Type de profil √† g√©n√©rer
        
    Returns:
        Dict avec client g√©n√©r√© + pr√©diction
    """
    try:
        logger.info(f"üé≠üéØ D√©mo compl√®te pour profil: {profile_type}")
        
        # 1. G√©n√©ration client fictif
        fake_client_data = generate_fake_client(profile_type)
        client_input = ClientInputAPI(**fake_client_data)
        
        # 2. Pr√©diction sur ce client
        input_dict = {
            "contract": client_input.contract,
            "tenure": client_input.tenure,
            "monthly_charges": client_input.monthly_charges,
            "total_charges": client_input.total_charges,
            "payment_method": client_input.payment_method,
            "internet_service": client_input.internet_service,
            "paperless_billing": client_input.paperless_billing
        }
        
        prediction_result = predictor.predict_single(input_dict, client_input.client_id)
        
        # 3. R√©ponse combin√©e
        demo_result = {
            "demo_info": {
                "profile_type": profile_type,
                "description": get_profile_description(profile_type),
                "timestamp": datetime.now().isoformat()
            },
            "generated_client": client_input.dict(),
            "prediction": {
                "churn_probability": prediction_result.churn_probability,
                "churn_prediction": prediction_result.churn_prediction,
                "risk_level": prediction_result.risk_level,
                "business_recommendation": prediction_result.business_recommendation,
                "confidence_score": prediction_result.confidence_score
            },
            "analysis": {
                "profile_matches_prediction": (
                    "high_risk" in profile_type and prediction_result.churn_prediction == 1
                ) or (
                    "stable" in profile_type and prediction_result.churn_prediction == 0
                ),
                "threshold_used": predictor.optimal_threshold
            }
        }
        
        logger.info(f"‚úÖ D√©mo termin√©e: {profile_type} ‚Üí P={prediction_result.churn_probability:.4f}")
        return demo_result
        
    except Exception as e:
        logger.error(f"‚ùå Erreur d√©mo compl√®te: {e}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Erreur d√©mo: {str(e)}"
        )

# =====================================================
# MAIN POUR EX√âCUTION DIRECTE
# =====================================================

if __name__ == "__main__":
    import uvicorn
    
    # Configuration pour d√©veloppement
    uvicorn.run(
        "api.main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )